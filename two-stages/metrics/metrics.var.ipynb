{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autoregression (VAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature and target columns\n",
    "df = pickle.load(open(\"./common/df.p\", \"rb\"))\n",
    "split_loc = pickle.load(open(\"./common/n_obs.p\", \"rb\"))\n",
    "n_splits = pickle.load(open(\"./common/n_splits.p\", \"rb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Stationarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary\n",
      "Stationary\n",
      "Stationary\n",
      "Stationary\n",
      "Stationary\n",
      "Stationary\n",
      "Stationary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cpu_usage             None\n",
       "memory_usage          None\n",
       "bandwidth_inbound     None\n",
       "bandwidth_outbound    None\n",
       "tps                   None\n",
       "tps_error             None\n",
       "response_time         None\n",
       "dtype: object"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_stationarity(data):\n",
    "    result = adfuller(data)\n",
    "    if result[1] < 0.05:\n",
    "        print(\"Stationary\")\n",
    "    else:\n",
    "        print(\"Non-Stationary\")\n",
    "\n",
    "# Apply this function to each column of your DataFrame\n",
    "df.apply(check_stationarity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return np.mean(2.0 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE for cpu_usage: 0.011390920257782638\n",
      "Average MSE for memory_usage: 1.44648013910263e-05\n",
      "Average MSE for bandwidth_inbound: 39795744.40062205\n",
      "Average MSE for bandwidth_outbound: 25708117.381725766\n",
      "Average MSE for tps: 0.6792662484422436\n",
      "Average MSE for tps_error: 0.18945668547028954\n",
      "Average MSE for response_time: 514198.4374786808\n",
      "-----------------------------------------\n",
      "Average MAPE for cpu_usage: 126.821342258525\n",
      "Average MAPE for memory_usage: 0.6659487996310652\n",
      "Average MAPE for bandwidth_inbound: 1076.484432610586\n",
      "Average MAPE for bandwidth_outbound: 1032.9534354092707\n",
      "Average MAPE for tps: 55.348696479226135\n",
      "Average MAPE for tps_error: inf\n",
      "Average MAPE for response_time: 49.42706820523503\n",
      "-----------------------------------------\n",
      "Average SMAPE for cpu_usage: 49.324512652706325\n",
      "Average SMAPE for memory_usage: 0.6671295296187708\n",
      "Average SMAPE for bandwidth_inbound: 79.81226331477602\n",
      "Average SMAPE for bandwidth_outbound: 73.20974637631039\n",
      "Average SMAPE for tps: 38.3364452356867\n",
      "Average SMAPE for tps_error: 159.8090712186724\n",
      "Average SMAPE for response_time: 39.93960690479583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_9852\\526402965.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_9852\\526402965.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_9852\\526402965.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_9852\\526402965.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
     ]
    }
   ],
   "source": [
    "window_size = len(df) // n_splits\n",
    "\n",
    "# Initialize a dictionary to store the MSEs, MAPEs, SMAPEs for each variable\n",
    "mse_dict = {var: [] for var in df.columns}\n",
    "mape_dict = {var: [] for var in df.columns}\n",
    "smape_dict = {var: [] for var in df.columns}\n",
    "\n",
    "for i in range(n_splits):\n",
    "    if i < n_splits - 1:\n",
    "        train, test = df[i*window_size:(i+1)*window_size], df[(i+1)*window_size:(i+2)*window_size]\n",
    "    else:  # If it's the last split, use the rest of the data for the test set\n",
    "        train, test = df[i*window_size:(i+1)*window_size], df[(i+1)*window_size:]\n",
    "    \n",
    "    # Fit the VAR model\n",
    "    model = VAR(train)\n",
    "    model_fit = model.fit(maxlags=5, ic='aic')  # Choose order of VAR with Akaike's Information Criterion\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    n_obs = len(test)  # Dynamically adjust the number of observations to forecast\n",
    "    predictions = model_fit.forecast(model_fit.model.endog, steps=n_obs)\n",
    "    \n",
    "    # Calculate mean squared error for each variable and store it in the dictionary\n",
    "    for j, var in enumerate(train.columns):\n",
    "        mse = mean_squared_error(test.iloc[:, j], predictions[:, j])\n",
    "        mape = mean_absolute_percentage_error(test.iloc[:, j].values, predictions[:, j])\n",
    "        smape_value = smape(test.iloc[:, j].values, predictions[:, j])\n",
    "        mse_dict[var].append(mse)\n",
    "        mape_dict[var].append(mape)\n",
    "        smape_dict[var].append(smape_value)\n",
    "\n",
    "# Compute and print the average MSE for each variable\n",
    "for var in mse_dict:\n",
    "    avg_mse = sum(mse_dict[var]) / len(mse_dict[var])\n",
    "    print(f'Average MSE for {var}: {avg_mse}')\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "# Compute and print the average MAPE for each variable\n",
    "for var in mape_dict:\n",
    "    avg_mape = sum(mape_dict[var]) / len(mape_dict[var])\n",
    "    print(f'Average MAPE for {var}: {avg_mape}')\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "# Compute and print the average SMAPE for each variable\n",
    "for var in smape_dict:\n",
    "    avg_smape = sum(smape_dict[var]) / len(smape_dict[var])\n",
    "    print(f'Average SMAPE for {var}: {avg_smape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data\n",
    "train_df, test_df = df[:split_loc], df[split_loc:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit a VAR model on the training dataset\n",
    "model = VAR(train_df)\n",
    "model_fit = model.fit(maxlags=15, ic='aic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions. The forecast method requires the number of steps to forecast and the data used for forecasting.\n",
    "lag_order = model_fit.k_ar\n",
    "predictions = model_fit.forecast(train_df.values[-lag_order:], len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the forecast returns an array, we can turn it back into a DataFrame to make it easier to work with.\n",
    "pred_df = pd.DataFrame(predictions, index=test_df.index, columns=test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE for cpu_usage: 50.14761760546931\n",
      "SMAPE for memory_usage: 0.5038814038188058\n",
      "SMAPE for bandwidth_inbound: 66.91174009146079\n",
      "SMAPE for bandwidth_outbound: 64.8449418735249\n",
      "SMAPE for tps: 42.76800022604646\n",
      "SMAPE for tps_error: 192.2790827548802\n",
      "SMAPE for response_time: 49.786979884606474\n"
     ]
    }
   ],
   "source": [
    "smape_values = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    smape_values[col] = smape(test_df[col], pred_df[col])\n",
    "    print(f'SMAPE for {col}: {smape_values[col]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_fit, open(\"./models/var.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
