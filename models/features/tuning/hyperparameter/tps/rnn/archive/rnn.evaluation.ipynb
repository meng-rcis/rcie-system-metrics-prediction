{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Evaluation: Base vs Tuning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Add path to the root folder\n",
    "sys.path.append('../../../../../')\n",
    "sys.path.append('../../../../features/prediction/')\n",
    "\n",
    "from models.features.prediction.putils.formatter import create_sequences\n",
    "from models.features.prediction.config.control import CONFIG\n",
    "from models.features.prediction.config.path import BASE_DATASET_PATH\n",
    "from models.features.prediction.manager import DataManager\n",
    "from models.features.prediction.putils.observation import compute_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "selected_feature = \"cpu_usage\"\n",
    "size_train, size_test = 1000, 250\n",
    "dataset = DataManager.LoadDataset(\"../../../../../\" + BASE_DATASET_PATH)[selected_feature]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "training_dataset = dataset[:size_train]\n",
    "scaled_training_dataset = scaler.fit_transform(training_dataset.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Performance Evaluation Function\n",
    "def evaluate_model_performance(model, X_test, y_test, scaler):\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform to get back to the original scale of the data\n",
    "    y_test_original = scaler.inverse_transform(y_test)\n",
    "    predictions_original = scaler.inverse_transform(predictions)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = compute_rmse(y_test_original, predictions_original)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "def create_rnn_2_layers_model(X, y, config):\n",
    "    # RNN Model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        SimpleRNN(\n",
    "            config.get(\"neurons_l1\", 50),\n",
    "            activation=config.get(\"activation_function_l1\", \"relu\"),\n",
    "            input_shape=(X.shape[1], X.shape[2]),\n",
    "            return_sequences=True,\n",
    "        )\n",
    "    )\n",
    "    model.add(SimpleRNN(config.get(\"neurons_l2\", 50), activation=config.get(\"activation_function_l2\", \"relu\")))\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=config.get(\"learning_rate\", 0.001)\n",
    "        ),\n",
    "        loss=\"mse\",\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        epochs=config.get(\"epochs\", 1),\n",
    "        verbose=config.get(\"verbose\", 0),\n",
    "        batch_size=config.get(\"batch_size\", 32),\n",
    "        validation_split=config.get(\"validation_split\", 0.2),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "Model RMSE: 0.031888830843966834\n"
     ]
    }
   ],
   "source": [
    "base_config = {\n",
    "    \"n_past\": 30,\n",
    "    \"epochs\": 50,\n",
    "    \"neurons\": 50,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"activation_function\": \"relu\",\n",
    "}\n",
    "\n",
    "n_past = base_config[\"n_past\"]\n",
    "n_future = CONFIG[\"PREDICTION_STEPS\"]\n",
    "testing_dataset = dataset[size_train - n_past : size_train + size_test]\n",
    "scaled_testing_dataset = scaler.transform(testing_dataset.values.reshape(-1, 1))\n",
    "\n",
    "X_train, y_train = create_sequences(scaled_training_dataset, n_past, n_future)\n",
    "model = create_rnn_2_layers_model(X_train, y_train, base_config)\n",
    "\n",
    "# Evaluate the model performance\n",
    "X_test, y_test = create_sequences(scaled_testing_dataset, n_past, n_future)\n",
    "rmse = evaluate_model_performance(model, X_test, y_test, scaler)\n",
    "print(\"Model RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuned Version (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step\n",
      "Model RMSE: 0.029282276628641527\n"
     ]
    }
   ],
   "source": [
    "# Best parameters:\n",
    "#               - n_past=36\n",
    "#               - epochs=74\n",
    "#               - batch_size=35\n",
    "#               - learning_rate=0.045884\n",
    "#               - neurons_l1=49\n",
    "#               - neurons_l2=55\n",
    "#               - activation_function_l1=sigmoid\n",
    "#               - activation_function_l2=sigmoid\n",
    "l2_config = {\n",
    "    \"n_past\": 36,\n",
    "    \"epochs\": 74,\n",
    "    \"batch_size\": 35,\n",
    "    \"learning_rate\": 0.045884,\n",
    "    \"neurons_l1\": 49,\n",
    "    \"neurons_l2\": 55,\n",
    "    \"activation_function_l1\": \"sigmoid\",\n",
    "    \"activation_function_l2\": \"sigmoid\",\n",
    "}\n",
    "\n",
    "n_past = l2_config[\"n_past\"]\n",
    "n_future = CONFIG[\"PREDICTION_STEPS\"]\n",
    "testing_dataset = dataset[size_train - n_past : size_train + size_test]\n",
    "scaled_testing_dataset = scaler.transform(testing_dataset.values.reshape(-1, 1))\n",
    "\n",
    "X_train, y_train = create_sequences(scaled_training_dataset, n_past, n_future)\n",
    "model = create_rnn_2_layers_model(X_train, y_train, l2_config)\n",
    "\n",
    "# Evaluate the model performance\n",
    "X_test, y_test = create_sequences(scaled_testing_dataset, n_past, n_future)\n",
    "rmse = evaluate_model_performance(model, X_test, y_test, scaler)\n",
    "print(\"Model RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
