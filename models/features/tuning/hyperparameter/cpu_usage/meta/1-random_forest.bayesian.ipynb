{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Linear Regression Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('./source/dataset.csv', index_col=0)\n",
    "X, y = df[['RNN', 'LSTM', 'CNN', 'GRU']], df['Actual']\n",
    "y_raw = df['Raw']\n",
    "# Get 1000 samples \n",
    "X_train = X[:1000]\n",
    "y_train = y[:1000]\n",
    "X_test = X[1000:]\n",
    "# y_test = y[1000:]\n",
    "y_test = y_raw[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: OrderedDict([('bootstrap', True), ('criterion', 'friedman_mse'), ('max_depth', 27), ('max_features', 'auto'), ('max_leaf_nodes', 17), ('min_impurity_decrease', 0.00035269496460264014), ('min_samples_leaf', 2), ('min_samples_split', 5), ('n_estimators', 110)])\n",
      "Best Score (RMSE): 0.023842113184446394\n"
     ]
    }
   ],
   "source": [
    "search_space = {\n",
    "    'n_estimators': Integer(100, 1000),\n",
    "    'max_depth': Integer(3, 30),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 20),\n",
    "    'max_features': Categorical(['auto', 'sqrt', 'log2']),\n",
    "    'max_leaf_nodes': Integer(10, 1000, \"log-uniform\"),\n",
    "    'min_impurity_decrease': Real(0.0, 1e-1),\n",
    "    'bootstrap': Categorical([True, False]),\n",
    "    'criterion': Categorical(['squared_error', 'absolute_error', 'friedman_mse', 'poisson'])  # Updated criterion values\n",
    "}\n",
    "\n",
    "# Create a RandomForestRegressor instance\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Custom scorer function to return RMSE\n",
    "def rmse_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return -np.sqrt(mean_squared_error(y, y_pred))  # Negative RMSE for maximization\n",
    "\n",
    "# Set up the BayesSearchCV\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=rf_model,\n",
    "    search_spaces=search_space,\n",
    "    n_iter=32,\n",
    "    scoring=rmse_scorer,  # Using custom RMSE scorer\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "best_params = bayes_search.best_params_\n",
    "best_score = -bayes_search.best_score_  # Converting back to positive RMSE\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score (RMSE):\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Score (RMSE): 0.04743107288994787\n",
      "Best Model Score (RMSE): 0.047208229161314404\n"
     ]
    }
   ],
   "source": [
    "# Print Score of the base model on the test set RMSE\n",
    "base_model = RandomForestRegressor(random_state=0)\n",
    "base_model.fit(X_train, y_train)\n",
    "y_pred = base_model.predict(X_test)\n",
    "base_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Base Model Score (RMSE):\", base_score)\n",
    "\n",
    "# Print Score of the model on the test set\n",
    "best_model = bayes_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "best_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Best Model Score (RMSE):\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Record\n",
    "\n",
    "Best Parameters: OrderedDict([('bootstrap', True), ('criterion', 'friedman_mse'), ('max_depth', 27), ('max_features', 'auto'), ('max_leaf_nodes', 17), ('min_impurity_decrease', 0.00035269496460264014), ('min_samples_leaf', 2), ('min_samples_split', 5), ('n_estimators', 110)])\n",
    "\n",
    "Base Model Score (RMSE): 0.025487677133160157\n",
    "\n",
    "Best Model Score (RMSE): 0.024724725455989666"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
