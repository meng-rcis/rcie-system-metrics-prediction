{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning RNN Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add path to the root folder\n",
    "sys.path.append('../../../../../')\n",
    "sys.path.append('../../../../features/prediction/')\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from models.features.prediction.putils.formatter import create_sequences\n",
    "from models.features.prediction.config.control import CONFIG\n",
    "from models.features.prediction.config.path import BASE_DATASET_PATH\n",
    "from models.features.prediction.manager import DataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNHyperparameterTuner:\n",
    "    def __init__(self, dataset, size_train, size_test):\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.dataset = dataset\n",
    "        self.scaled_dataset = self.scaler.fit_transform(\n",
    "            self.dataset.values.reshape(-1, 1)\n",
    "        )\n",
    "        self.scaled_training_dataset = self.scaled_dataset[:size_train]\n",
    "        self.scaled_testing_dataset = self.scaled_dataset[\n",
    "            size_train : size_train + size_test\n",
    "        ]\n",
    "\n",
    "    def train_model(self, config):\n",
    "        # Group data for RNN\n",
    "        X, y = create_sequences(\n",
    "            self.scaled_training_dataset,\n",
    "            config.get(\"n_past\", 5),\n",
    "            config.get(\"steps\", 1),\n",
    "        )\n",
    "\n",
    "        # RNN Model\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            SimpleRNN(\n",
    "                config.get(\"neurons\", 50),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(X.shape[1], X.shape[2]),\n",
    "                return_sequences=True,\n",
    "            )\n",
    "        )\n",
    "        model.add(SimpleRNN(config.get(\"neurons\", 50), activation=\"relu\"))\n",
    "        model.add(Dense(y.shape[1]))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=config.get(\"learning_rate\", 0.001)\n",
    "            ),\n",
    "            loss=\"mse\",\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=config.get(\"epochs\", 1),\n",
    "            verbose=config.get(\"verbose\", 0),\n",
    "            batch_size=config.get(\"batch_size\", 32),\n",
    "            validation_split=config.get(\"validation_split\", 0.2),\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    def evaluate_model(self, model, config):\n",
    "        X_test, y_test = create_sequences(\n",
    "            self.scaled_testing_dataset,\n",
    "            config.get(\"n_past\", 5),\n",
    "            config.get(\"steps\", 1),\n",
    "        )\n",
    "        # Evaluate the model on the test set\n",
    "        test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "        return test_loss\n",
    "\n",
    "    def random_search(self, n_iterations):\n",
    "        best_score = float(\"inf\")\n",
    "        best_config = None\n",
    "\n",
    "        for _ in range(n_iterations):\n",
    "            config = {\n",
    "                \"n_past\": random.choice([5, 10, 30, 50]),\n",
    "                \"steps\": CONFIG[\"PREDICTION_STEPS\"],\n",
    "                \"epochs\": random.choice([10, 20, 50, 100]),\n",
    "                \"batch_size\": random.choice([16, 32, 64]),\n",
    "                \"learning_rate\": random.choice([0.001, 0.01, 0.1]),\n",
    "                \"neurons\": random.choice([30, 50, 70]),\n",
    "            }\n",
    "\n",
    "            model = self.train_model(config)\n",
    "            score = self.evaluate_model(model, config)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score, best_config = score, config\n",
    "                print(f\"New best score: {best_score} with config: {best_config}\")\n",
    "\n",
    "        print(\"Best Configuration:\", best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.0023586328607052565 with config: {'n_past': 30, 'steps': 5, 'epochs': 20, 'batch_size': 16, 'learning_rate': 0.1, 'neurons': 30}\n",
      "New best score: 0.0010145725682377815 with config: {'n_past': 5, 'steps': 5, 'epochs': 20, 'batch_size': 16, 'learning_rate': 0.01, 'neurons': 70}\n",
      "New best score: 0.0006197203765623271 with config: {'n_past': 30, 'steps': 5, 'epochs': 100, 'batch_size': 16, 'learning_rate': 0.01, 'neurons': 70}\n",
      "Best Configuration: {'n_past': 30, 'steps': 5, 'epochs': 100, 'batch_size': 16, 'learning_rate': 0.01, 'neurons': 70}\n"
     ]
    }
   ],
   "source": [
    "selected_feature = \"cpu_usage\"\n",
    "size_train, size_test = 1000, 250\n",
    "dataset = DataManager.LoadDataset(\"../../../../../\" + BASE_DATASET_PATH)[selected_feature]\n",
    "\n",
    "# Usage\n",
    "tuner = RNNHyperparameterTuner(dataset, size_train, size_test)\n",
    "tuner.random_search(n_iterations=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
