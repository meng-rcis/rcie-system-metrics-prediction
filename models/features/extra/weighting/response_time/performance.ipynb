{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Prediction Observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "IS_FILTERED = True\n",
    "ARCHIVED = None\n",
    "\n",
    "SHOW_HEADER = True\n",
    "SHOW_LAST_APPEARANCE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../../../prediction')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from putils.observation import compute_rmse, compute_mae, compute_mape, load_data_from_tuned_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dfs = {\n",
    "    \"l1\": load_data_from_tuned_folder(\"l1\", last_appearance=SHOW_LAST_APPEARANCE),\n",
    "    \"l2\": load_data_from_tuned_folder(\"l2\", last_appearance=SHOW_LAST_APPEARANCE),\n",
    "    \"l3\": load_data_from_tuned_folder(\"l3\", last_appearance=SHOW_LAST_APPEARANCE),\n",
    "}\n",
    "\n",
    "# Make L1 and L2 data have the same length with L3 if SHOW_LAST_APPEARANCE = None\n",
    "if SHOW_LAST_APPEARANCE is None:\n",
    "    dfs[\"l1\"] = dfs[\"l1\"].tail(len(dfs[\"l3\"]))\n",
    "    dfs[\"l2\"] = dfs[\"l2\"].tail(len(dfs[\"l3\"]))\n",
    "\n",
    "# Indicate which columns to ignore\n",
    "IGNORED_COLS = [\"Time\", \"Actual\"] # No need to include \"FormattedTime\" because it is used as index\n",
    "if IS_FILTERED: IGNORED_COLS.append(\"Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer l1\n",
      "ARIMA - RMSE: 1049.1569, MAE: 746.8066, MAPE: 67.70%\n",
      "SARIMA - RMSE: 1049.1745, MAE: 745.4478, MAPE: 67.46%\n",
      "ETS - RMSE: 1459.6899, MAE: 1024.6374, MAPE: 94.28%\n",
      "RNN - RMSE: 642.3348, MAE: 495.1957, MAPE: 49.11%\n",
      "LSTM - RMSE: 665.7295, MAE: 516.6156, MAPE: 50.66%\n",
      "CNN - RMSE: 741.9941, MAE: 576.8489, MAPE: 58.00%\n",
      "GRU - RMSE: 649.1460, MAE: 501.2780, MAPE: 49.63%\n",
      "TCN - RMSE: 847.4626, MAE: 667.0838, MAPE: 66.95%\n",
      "------------------\n",
      "Layer l2\n",
      "LINEAR_REGRESSION - RMSE: 637.3582, MAE: 489.8354, MAPE: 47.91%\n",
      "RANDOM_FOREST - RMSE: 649.3304, MAE: 498.4929, MAPE: 48.91%\n",
      "FEEDFORWARD_NEURAL_NETWORK - RMSE: 650.6872, MAE: 498.2397, MAPE: 48.63%\n",
      "------------------\n",
      "Layer l3\n",
      "Predicted - RMSE: 640.2040, MAE: 491.5452, MAPE: 48.15%\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE, MAE, and MAPE for each model\n",
    "for key, df in dfs.items():\n",
    "    print(\"Layer\", key)\n",
    "    for column in df.columns:\n",
    "        if column not in IGNORED_COLS:\n",
    "            actual = df[\"Raw\"] if IS_FILTERED else df[\"Actual\"]\n",
    "            rmse = compute_rmse(actual, df[column])\n",
    "            mape = compute_mape(actual, df[column])\n",
    "            mae = compute_mae(actual, df[column])\n",
    "            print(f\"{column} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_32648\\4117765964.py:37: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result = np.exp(alpha * -rmses[column]) / rmse_sum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final weights: {'ARIMA': 0.125, 'SARIMA': 0.125, 'ETS': 0.125, 'RNN': 0.125, 'LSTM': 0.125, 'CNN': 0.125, 'GRU': 0.125, 'TCN': 0.125}\n"
     ]
    }
   ],
   "source": [
    "# Get data from d1\n",
    "d1 = dfs[\"l1\"]\n",
    "d1 = d1.drop(columns=[\"Time\", \"Actual\"])\n",
    "alpha = 100\n",
    "\n",
    "# Dict of models with their initial weights (1 / number of models)\n",
    "weights = {}\n",
    "for column in d1.columns:\n",
    "    if column != \"Average\" and column != \"Raw\":\n",
    "        weights[column] = 1 / (len(d1.columns) - 1) # -1 because the column \"Raw\" is ignored\n",
    "\n",
    "# Create a new column for the average value\n",
    "d1[\"Average\"] = None\n",
    "\n",
    "# Loop through each row and compute the weighted average\n",
    "count = 0\n",
    "for index, row in d1.iterrows():\n",
    "    # Find the average value with weight of the row \n",
    "    total = 0\n",
    "    for column in d1.columns:\n",
    "        if column != \"Average\" and column != \"Raw\":\n",
    "            total += row[column] * weights[column]\n",
    "    # Add the average value to the row\n",
    "    d1.loc[index, \"Average\"] = total\n",
    "    # Update the weights every 5 rows\n",
    "    if count % 5 == 0:\n",
    "        # Compute RMSE of each model from 0 to count - 1\n",
    "        rmses = {}\n",
    "        for column in d1.columns:\n",
    "            if column != \"Average\" and column != \"Raw\":\n",
    "                rmses[column] = compute_rmse(d1[\"Raw\"][:count], d1[column][:count])\n",
    "        # Compute the sum of exponential RMSEs [exp(alpha * -rmse)]\n",
    "        rmse_sum = sum([np.exp(alpha * -rmse) for rmse in rmses.values()])\n",
    "        # Update the weights\n",
    "        for column in d1.columns:\n",
    "            if column != \"Average\" and column != \"Raw\":\n",
    "                result = np.exp(alpha * -rmses[column]) / rmse_sum\n",
    "                # Check if nan\n",
    "                if np.isnan(result) == False:\n",
    "                    weights[column] = result\n",
    "    # Increment count\n",
    "    count += 1\n",
    "\n",
    "print(f\"final weights: {weights}\")\n",
    "\n",
    "# Save the data into new file\n",
    "d1.to_csv(\"l1_weighted_average.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
