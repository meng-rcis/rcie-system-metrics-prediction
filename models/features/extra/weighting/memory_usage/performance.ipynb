{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Prediction Observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "IS_FILTERED = True\n",
    "ARCHIVED = None\n",
    "\n",
    "SHOW_HEADER = True\n",
    "SHOW_LAST_APPEARANCE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../../../prediction')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from putils.observation import compute_rmse, compute_mae, compute_mape, load_data_from_tuned_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dfs = {\n",
    "    \"l1\": load_data_from_tuned_folder(\"l1\", last_appearance=SHOW_LAST_APPEARANCE),\n",
    "    \"l2\": load_data_from_tuned_folder(\"l2\", last_appearance=SHOW_LAST_APPEARANCE),\n",
    "    \"l3\": load_data_from_tuned_folder(\"l3\", last_appearance=SHOW_LAST_APPEARANCE),\n",
    "}\n",
    "\n",
    "# Make L1 and L2 data have the same length with L3 if SHOW_LAST_APPEARANCE = None\n",
    "if SHOW_LAST_APPEARANCE is None:\n",
    "    dfs[\"l1\"] = dfs[\"l1\"].tail(len(dfs[\"l3\"]))\n",
    "    dfs[\"l2\"] = dfs[\"l2\"].tail(len(dfs[\"l3\"]))\n",
    "\n",
    "# Indicate which columns to ignore\n",
    "IGNORED_COLS = [\"Time\", \"Actual\"] # No need to include \"FormattedTime\" because it is used as index\n",
    "if IS_FILTERED: IGNORED_COLS.append(\"Raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer l1\n",
      "ARIMA - RMSE: 0.0228, MAE: 0.0153, MAPE: 2.80%\n",
      "RNN - RMSE: 0.0149, MAE: 0.0103, MAPE: 1.88%\n",
      "LSTM - RMSE: 0.0155, MAE: 0.0106, MAPE: 1.94%\n",
      "CNN - RMSE: 0.0159, MAE: 0.0108, MAPE: 1.97%\n",
      "GRU - RMSE: 0.0152, MAE: 0.0105, MAPE: 1.92%\n",
      "------------------\n",
      "Layer l2\n",
      "LINEAR_REGRESSION - RMSE: 0.0149, MAE: 0.0103, MAPE: 1.87%\n",
      "RANDOM_FOREST - RMSE: 0.0153, MAE: 0.0105, MAPE: 1.90%\n",
      "FEEDFORWARD_NEURAL_NETWORK - RMSE: 0.0149, MAE: 0.0103, MAPE: 1.87%\n",
      "------------------\n",
      "Layer l3\n",
      "Predicted - RMSE: 0.0149, MAE: 0.0103, MAPE: 1.87%\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE, MAE, and MAPE for each model\n",
    "for key, df in dfs.items():\n",
    "    print(\"Layer\", key)\n",
    "    for column in df.columns:\n",
    "        if column not in IGNORED_COLS:\n",
    "            actual = df[\"Raw\"] if IS_FILTERED else df[\"Actual\"]\n",
    "            rmse = compute_rmse(actual, df[column])\n",
    "            mape = compute_mape(actual, df[column])\n",
    "            mae = compute_mae(actual, df[column])\n",
    "            print(f\"{column} - RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.2f}%\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final weights: {'ARIMA': 0.10612829763874386, 'RNN': 0.23460247819115762, 'LSTM': 0.21951357191482349, 'CNN': 0.21231286556396534, 'GRU': 0.22744278669130955}\n"
     ]
    }
   ],
   "source": [
    "# Get data from d1\n",
    "d1 = dfs[\"l1\"]\n",
    "d1 = d1.drop(columns=[\"Time\", \"Actual\"])\n",
    "alpha = 100\n",
    "\n",
    "# Dict of models with their initial weights (1 / number of models)\n",
    "weights = {}\n",
    "for column in d1.columns:\n",
    "    if column != \"Average\" and column != \"Raw\":\n",
    "        weights[column] = 1 / (len(d1.columns) - 1) # -1 because the column \"Raw\" is ignored\n",
    "\n",
    "# Create a new column for the average value\n",
    "d1[\"Average\"] = None\n",
    "\n",
    "# Loop through each row and compute the weighted average\n",
    "count = 0\n",
    "for index, row in d1.iterrows():\n",
    "    # Find the average value with weight of the row \n",
    "    total = 0\n",
    "    for column in d1.columns:\n",
    "        if column != \"Average\" and column != \"Raw\":\n",
    "            total += row[column] * weights[column]\n",
    "    # Add the average value to the row\n",
    "    d1.loc[index, \"Average\"] = total\n",
    "    # Compute RMSE of each model from 0 to count - 1\n",
    "    rmses = {}\n",
    "    for column in d1.columns:\n",
    "        if column != \"Average\" and column != \"Raw\":\n",
    "            rmses[column] = compute_rmse(d1[\"Raw\"][:count], d1[column][:count])\n",
    "    # Compute the sum of exponential RMSEs [exp(alpha * -rmse)]\n",
    "    rmse_sum = sum([np.exp(alpha * -rmse) for rmse in rmses.values()])\n",
    "    # Update the weights\n",
    "    for column in d1.columns:\n",
    "        if column != \"Average\" and column != \"Raw\":\n",
    "            result = np.exp(alpha * -rmses[column]) / rmse_sum\n",
    "            # Check if nan\n",
    "            if np.isnan(result) == False:\n",
    "                weights[column] = result\n",
    "    # Increment count\n",
    "    count += 1\n",
    "\n",
    "print(f\"final weights: {weights}\")\n",
    "\n",
    "# Save the data into new file\n",
    "d1.to_csv(\"l1_weighted_average.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
